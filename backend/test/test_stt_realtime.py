import asyncio
import wave
import os
from livekit.plugins import aliyun
from livekit import rtc
import aiohttp
from dotenv import load_dotenv

load_dotenv()


async def test_with_real_audio():
    """ä½¿ç”¨çœŸå®éŸ³é¢‘æ–‡ä»¶æµ‹è¯•"""

    audio_file = "test_chinese_1.wav"

    # è¯»å–å¹¶è½¬æ¢éŸ³é¢‘åˆ° 16kHz
    print("ğŸ”„ è½¬æ¢éŸ³é¢‘åˆ° 16kHz...")

    try:
        import numpy as np
        from scipy import signal

        # è¯»å–åŸå§‹éŸ³é¢‘
        with wave.open(audio_file, 'rb') as wf:
            original_rate = wf.getframerate()
            channels = wf.getnchannels()
            sample_width = wf.getsampwidth()
            frames = wf.readframes(wf.getnframes())

            print(f"ğŸ“Š åŸå§‹éŸ³é¢‘: {original_rate} Hz")

        # è½¬æ¢ä¸º numpy æ•°ç»„
        audio_data = np.frombuffer(frames, dtype=np.int16)

        # é‡é‡‡æ ·åˆ° 16kHz
        target_rate = 16000
        num_samples = int(len(audio_data) * target_rate / original_rate)
        resampled = signal.resample(audio_data, num_samples)
        resampled = resampled.astype(np.int16)

        # ä¿å­˜è½¬æ¢åçš„éŸ³é¢‘
        converted_file = "com_16k.wav"
        with wave.open(converted_file, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)
            wf.setframerate(16000)
            wf.writeframes(resampled.tobytes())

        print(f"âœ… å·²è½¬æ¢ä¸º 16kHz: {converted_file}")
        audio_file = converted_file
        sample_rate = 16000

    except ImportError:
        print("âš ï¸ éœ€è¦å®‰è£…: pip install numpy scipy")
        return

    # åˆ›å»º session
    session = aiohttp.ClientSession()

    try:
        # åˆ›å»º STT
        stt = aliyun.STT(
            language='zh-CN',
            model='paraformer-realtime-v2',
            max_sentence_silence=800,
            api_key=os.getenv('DASHSCOPE_API_KEY'),
            http_session=session
        )

        print("âœ… STT å®ä¾‹åˆ›å»ºæˆåŠŸ")

        # åˆ›å»ºéŸ³é¢‘æµ
        stream = stt.stream()
        print("âœ… Stream åˆ›å»ºæˆåŠŸ")

        # ç­‰å¾…åˆå§‹åŒ–
        await asyncio.sleep(1)

        # ç›‘å¬è¯†åˆ«ç»“æœ
        async def listen_results():
            print("ğŸ¯ å¼€å§‹ç›‘å¬ STT ç»“æœ...")
            try:
                async for event in stream:
                    print(f"ğŸ”” æ”¶åˆ°äº‹ä»¶: type={event.type}")
                    if event.alternatives:
                        text = event.alternatives[0].text
                        is_final = event.is_final
                        print(f"{'ğŸŸ¢ æœ€ç»ˆ' if is_final else 'ğŸŸ¡ ä¸­é—´'} è¯†åˆ«: '{text}'")
            except Exception as e:
                print(f"âŒ ç›‘å¬å‡ºé”™: {e}")

        # å¯åŠ¨ç›‘å¬
        listen_task = asyncio.create_task(listen_results())

        # æ¨é€éŸ³é¢‘
        print("ğŸ“¡ å¼€å§‹æ¨é€éŸ³é¢‘...")
        with wave.open(audio_file, 'rb') as wf:
            chunk_size = int(16000 * 0.1)  # 100ms
            frame_count = 0

            while True:
                data = wf.readframes(chunk_size)
                if not data:
                    break

                audio_frame = rtc.AudioFrame(
                    data=data,
                    sample_rate=16000,
                    num_channels=1,
                    samples_per_channel=len(data) // 2
                )

                stream.push_frame(audio_frame)
                frame_count += 1

                if frame_count % 10 == 0:
                    print(f"   å·²æ¨é€ {frame_count} å¸§...")

                await asyncio.sleep(0.1)

        print(f"âœ… éŸ³é¢‘æ¨é€å®Œæˆï¼Œå…± {frame_count} å¸§")

        # ç­‰å¾…è¯†åˆ«
        print("â³ ç­‰å¾…è¯†åˆ«å®Œæˆ...")
        await asyncio.sleep(5)

        # å…³é—­
        await stream.aclose()

        try:
            await asyncio.wait_for(listen_task, timeout=2)
        except asyncio.TimeoutError:
            listen_task.cancel()

        print("ğŸ æµ‹è¯•å®Œæˆ")

    finally:
        await session.close()


asyncio.run(test_with_real_audio())